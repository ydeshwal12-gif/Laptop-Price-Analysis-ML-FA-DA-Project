{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda8a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laptop Price Analysis — Ready-to-run Jupyter-style Python notebook\n",
    "# Save this file as `laptop_price_analysis.py` or open it in Jupyter/VS Code (it uses cell markers # %% ).\n",
    "# Instructions:\n",
    "# 1. Put the laptop CSV file in the same folder and name it `laptop_prices.csv` (or change the path below).\n",
    "# 2. Run the cells in order. If any library is missing, install it via pip (see cell below).\n",
    "\n",
    "# %%\n",
    "# 0) Install required libraries (run once if needed)\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn joblib\n",
    "# If you'd like to try XGBoost uncomment the next line (optional):\n",
    "# !pip install xgboost\n",
    "\n",
    "# %%\n",
    "# 1) Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# %%\n",
    "# 2) Load the dataset\n",
    "# Put your CSV in the same folder as this notebook and name it 'laptop_prices.csv'\n",
    "DATA_PATH = 'laptop_prices.csv'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"{DATA_PATH} not found. Please place the CSV in the working directory and try again.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, encoding='ISO-8859-1')\n",
    "print('Dataset loaded — shape:', df.shape)\n",
    "\n",
    "# Quick peek\n",
    "print('\\n--- head ---')\n",
    "print(df.head(3).T)\n",
    "\n",
    "# %%\n",
    "# 3) Basic info & missing values\n",
    "print('\\n--- info ---')\n",
    "print(df.info())\n",
    "print('\\n--- missing values ---')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# %%\n",
    "# 4) Quick descriptive statistics\n",
    "print('\\n--- describe ---')\n",
    "print(df.describe(include='all').T)\n",
    "\n",
    "# %%\n",
    "# 5) Feature engineering\n",
    "# Create a Pixel-Per-Inch (PPI) feature from ScreenW, ScreenH and Inches (if available)\n",
    "if {'ScreenW', 'ScreenH', 'Inches'}.issubset(df.columns):\n",
    "    df['PPI'] = ((df['ScreenW']**2 + df['ScreenH']**2)**0.5 / df['Inches']).round(2)\n",
    "else:\n",
    "    df['PPI'] = np.nan\n",
    "\n",
    "# Convert Touchscreen, IPSpanel, RetinaDisplay strings (Yes/No) to 0/1 if necessary\n",
    "for col in ['Touchscreen', 'IPSpanel', 'RetinaDisplay']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0}).fillna(df[col])\n",
    "\n",
    "# View new columns\n",
    "print('\\n--- columns after feature engineering ---')\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# %%\n",
    "# 6) Exploratory Data Analysis (plots)\n",
    "# A selection of useful EDA visuals; run interactively to inspect\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['Price_euros'], bins=40, kde=True)\n",
    "plt.title('Distribution of Laptop Prices (Euros)')\n",
    "plt.xlabel('Price_euros')\n",
    "plt.show()\n",
    "\n",
    "# Company counts\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(y='Company', data=df, order=df['Company'].value_counts().index)\n",
    "plt.title('Number of laptops per Company')\n",
    "plt.show()\n",
    "\n",
    "# Price by Company (boxplot)\n",
    "plt.figure(figsize=(14,5))\n",
    "sns.boxplot(x='Company', y='Price_euros', data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Price distribution by Company')\n",
    "plt.show()\n",
    "\n",
    "# Touchscreen vs price\n",
    "if 'Touchscreen' in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x='Touchscreen', y='Price_euros', data=df)\n",
    "plt.title('Touchscreen vs Price')\n",
    "plt.show()\n",
    "\n",
    "# RAM vs Price (barplot with mean)\n",
    "if 'Ram' in df.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "sns.barplot(x='Ram', y='Price_euros', data=df, estimator=np.mean)\n",
    "plt.title('Average Price by RAM')\n",
    "plt.show()\n",
    "\n",
    "# PPI vs Price scatter\n",
    "if 'PPI' in df.columns:\n",
    "    plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(x='PPI', y='Price_euros', data=df)\n",
    "plt.title('PPI vs Price')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# 7) Preprocessing for modeling\n",
    "# Select features to use. We'll drop columns that are high-cardinality product names or duplicates.\n",
    "DROP_COLS = ['Product'] if 'Product' in df.columns else []\n",
    "# Keep relevant columns (adjust according to your dataset)\n",
    "candidate_features = [\n",
    "    'Company','TypeName','Inches','Ram','OS','Weight','Touchscreen','IPSpanel','RetinaDisplay',\n",
    "    'PPI','CPU_company','CPU_freq','PrimaryStorage','PrimaryStorageType','SecondaryStorage','SecondaryStorageType',\n",
    "    'GPU_company'\n",
    "]\n",
    "\n",
    "# Keep only those that exist in the df\n",
    "features = [c for c in candidate_features if c in df.columns]\n",
    "print('\\nUsing features:', features)\n",
    "\n",
    "# Target\n",
    "TARGET = 'Price_euros'\n",
    "if TARGET not in df.columns:\n",
    "    raise KeyError(f\"Target column '{TARGET}' not found in dataset.\")\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "# Quick cleanup: if any boolean-like columns remain as strings map them\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    if X[col].nunique() == 2 and set(X[col].dropna().unique()) <= set(['Yes','No']):\n",
    "        X[col] = X[col].map({'Yes':1,'No':0})\n",
    "\n",
    "# Show head\n",
    "print('\\n--- X sample ---')\n",
    "print(X.head())\n",
    "\n",
    "# %%\n",
    "# 8) Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('\\nTrain size:', X_train.shape, 'Test size:', X_test.shape)\n",
    "\n",
    "# %%\n",
    "# 9) Build preprocessing pipeline\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print('\\nNumeric columns:', numeric_cols)\n",
    "print('Categorical columns:', cat_cols)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# %%\n",
    "# 10) Modeling — baseline (Linear Regression), then RandomForest with GridSearch\n",
    "# Baseline: Linear Regression\n",
    "pipe_lr = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = pipe_lr.predict(X_test)\n",
    "print('\\nLinear Regression — MSE:', mean_squared_error(y_test, y_pred_lr), 'R2:', r2_score(y_test, y_pred_lr))\n",
    "\n",
    "# %%\n",
    "# Random Forest with a small GridSearch for better performance\n",
    "pipe_rf = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(pipe_rf, param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=1)\n",
    "gsearch.fit(X_train, y_train)\n",
    "\n",
    "print('\\nBest params:', gsearch.best_params_)\n",
    "best_rf = gsearch.best_estimator_\n",
    "\n",
    "# Evaluate\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "print('RandomForest — MSE:', mean_squared_error(y_test, y_pred_rf), 'R2:', r2_score(y_test, y_pred_rf))\n",
    "\n",
    "# %%\n",
    "# 11) Feature importance (for RandomForest) — need to extract names after one-hot encoding\n",
    "# Get feature names from preprocessor\n",
    "onehot_cols = []\n",
    "if cat_cols:\n",
    "    # get feature names for onehot\n",
    "    ohe = best_rf.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "    cat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "else:\n",
    "    cat_names = []\n",
    "\n",
    "feature_names = numeric_cols + cat_names\n",
    "importances = best_rf.named_steps['regressor'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(30)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=feat_imp.values, y=feat_imp.index)\n",
    "plt.title('Top 30 Feature Importances (RandomForest)')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# 12) Final evaluation with selected model and simple residual plot\n",
    "model = best_rf\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\nFinal model R2:', r2_score(y_test, y_pred))\n",
    "print('Final model RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual vs Predicted — Final Model')\n",
    "plt.show()\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(residuals, bins=40, kde=True)\n",
    "plt.title('Residuals Distribution')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# 13) Save the trained model\n",
    "MODEL_PATH = 'laptop_price_model.joblib'\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "print(f'Model saved to {MODEL_PATH}')\n",
    "\n",
    "# %%\n",
    "# 14) Example: load model & make a single prediction\n",
    "# Build a sample datapoint using the feature format — adapt values to your dataset\n",
    "sample = X_test.iloc[0:1].copy()\n",
    "print('\\nSample input:')\n",
    "print(sample)\n",
    "\n",
    "loaded = joblib.load(MODEL_PATH)\n",
    "sample_pred = loaded.predict(sample)\n",
    "print('\\nPredicted price for sample:', sample_pred[0])\n",
    "print('Actual price:', y_test.iloc[0])\n",
    "\n",
    "# %%\n",
    "# 15) Next steps (suggestions)\n",
    "# - Try GradientBoostingRegressor or XGBoost for better performance.\n",
    "# - Use more advanced hyperparameter tuning (RandomizedSearchCV, larger grids).\n",
    "# - Do more feature engineering (parse CPU_model, GPU_model, storage sizes as categories).\n",
    "# - If dataset is large, consider using categorical encoding methods like TargetEncoder.\n",
    "# - Save preprocessor and model separately if needed for deployment.\n",
    "\n",
    "print('\\nNotebook finished. Good luck!')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
